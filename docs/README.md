# ğŸ“š DocumentaÃ§Ã£o da API - Go Crawler

## ğŸš€ Acesso RÃ¡pido

- **ğŸ“– DocumentaÃ§Ã£o Interativa (Swagger UI):** [http://localhost:8081/docs](http://localhost:8081/docs)
- **ğŸ  Interface Web Principal:** [http://localhost:8081/](http://localhost:8081/)
- **ğŸ’š Health Check:** [http://localhost:8081/health](http://localhost:8081/health)

## ğŸ“‹ VisÃ£o Geral

A **Go Crawler API** Ã© um sistema inteligente de crawling de imÃ³veis que utiliza aprendizado de mÃ¡quina para classificar pÃ¡ginas automaticamente, distinguindo entre:

- **ğŸ“„ PÃ¡ginas de CatÃ¡logo**: Listagens com mÃºltiplos imÃ³veis
- **ğŸ  PÃ¡ginas de Propriedade**: Detalhes de imÃ³veis individuais

### ğŸ¯ PrecisÃ£o Atual: **80%**

ApÃ³s treinamento com **42 URLs de propriedades reais**, o sistema alcanÃ§ou 80% de precisÃ£o na classificaÃ§Ã£o automÃ¡tica.

## ğŸ”§ Principais Funcionalidades

### 1. ğŸ¤– **Sistema de ClassificaÃ§Ã£o Inteligente**
- **MÃ©todo Recomendado**: AnÃ¡lise baseada em conteÃºdo (`/content/*`)
- **MÃ©todo Legado**: AnÃ¡lise baseada em URL (`/patterns/*`)
- **Aprendizado ContÃ­nuo**: Melhora com mais exemplos de treinamento

### 2. ğŸ™ï¸ **Gerenciamento de Cidades**
- Descoberta automÃ¡tica de sites imobiliÃ¡rios
- ValidaÃ§Ã£o e estatÃ­sticas de sites
- Gerenciamento por regiÃ£o

### 3. ğŸ” **Busca AvanÃ§ada**
- Filtros mÃºltiplos (cidade, tipo, valor, Ã¡rea, quartos)
- Busca textual em descriÃ§Ãµes
- PaginaÃ§Ã£o eficiente

### 4. ğŸ“Š **Monitoramento e EstatÃ­sticas**
- Dashboard web completo
- MÃ©tricas de performance
- Logs detalhados de crawling

## ğŸ› ï¸ Endpoints Principais

### ğŸ  **Propriedades**
```
GET    /properties              # Listar propriedades (paginado)
GET    /properties/search       # Busca avanÃ§ada com filtros
```

### ğŸ¤– **Crawler Inteligente**
```
POST   /crawler/trigger         # Iniciar crawling com classificaÃ§Ã£o automÃ¡tica
POST   /crawler/cleanup         # Limpar banco de dados
```

### ğŸ§  **Aprendizado de ConteÃºdo (RECOMENDADO)**
```
POST   /content/learn/catalog   # Treinar com pÃ¡ginas de catÃ¡logo
POST   /content/learn/property  # Treinar com pÃ¡ginas de propriedades
POST   /content/classify        # Classificar pÃ¡gina por conteÃºdo
GET    /content/patterns        # Ver padrÃµes aprendidos
```

### ğŸ™ï¸ **Gerenciamento de Cidades**
```
POST   /cities/discover-sites   # Descobrir sites de uma cidade
GET    /cities                  # Listar todas as cidades
GET    /cities/{city}           # InformaÃ§Ãµes de uma cidade
GET    /cities/{city}/sites     # Sites de uma cidade
```

## ğŸ“– Como Usar a DocumentaÃ§Ã£o

### 1. **Acesse a DocumentaÃ§Ã£o Interativa**
```
http://localhost:8081/docs
```

### 2. **Explore os Endpoints**
- Cada endpoint tem exemplos de request/response
- VocÃª pode testar diretamente na interface
- Schemas detalhados para todos os objetos

### 3. **Teste os Endpoints**
- Use o botÃ£o "Try it out" em cada endpoint
- Modifique os parÃ¢metros conforme necessÃ¡rio
- Veja as respostas em tempo real

## ğŸ¯ Fluxo Recomendado de Uso

### 1. **Descobrir Sites de uma Cidade**
```bash
curl -X POST "http://localhost:8081/cities/discover-sites" \
  -H "Content-Type: application/json" \
  -d '{"city": "Muzambinho", "limit": 10}'
```

### 2. **Treinar o Sistema (Opcional)**
```bash
# Treinar com pÃ¡ginas de propriedades
curl -X POST "http://localhost:8081/content/learn/property" \
  -H "Content-Type: application/json" \
  -d '{"urls": ["https://example.com/imovel/123"]}'
```

### 3. **Iniciar Crawling Inteligente**
```bash
curl -X POST "http://localhost:8081/crawler/trigger" \
  -H "Content-Type: application/json" \
  -d '{"cities": ["Muzambinho"], "max_pages": 15}'
```

### 4. **Buscar Propriedades Coletadas**
```bash
curl "http://localhost:8081/properties?cidade=Muzambinho&page=1&page_size=10"
```

## ğŸ” Exemplos de ClassificaÃ§Ã£o

### âœ… **PÃ¡gina de Propriedade Individual**
```json
{
  "url": "https://www.imobr.com.br/detalhes/casa/venda/muzambinho/mg/bairro-centro/suites-0/banheiros-3/vagas-3/3462038/1",
  "type": "property",
  "confidence": 0.90
}
```

### ğŸš¨ **PÃ¡gina de CatÃ¡logo**
```json
{
  "url": "https://www.mgfimoveis.com.br/venda/casa/mg-muzambinho",
  "type": "catalog",
  "confidence": 0.95
}
```

## ğŸ“Š MÃ©tricas de Performance

| MÃ©trica | Valor | DescriÃ§Ã£o |
|---------|-------|-----------|
| **PrecisÃ£o** | 80% | ClassificaÃ§Ã£o correta de pÃ¡ginas |
| **Rate Limit** | 100 req/h | Limite geral de requisiÃ§Ãµes |
| **Crawler Limit** | 50 req/h | Limite para endpoints de crawling |
| **PadrÃµes Aprendidos** | 9+ | PadrÃµes de propriedades no sistema |

## ğŸš¨ Notas Importantes

### âš ï¸ **Rate Limiting**
- **Endpoints Gerais**: 100 requisiÃ§Ãµes por hora
- **Endpoints de Crawler**: 50 requisiÃ§Ãµes por hora
- Headers de rate limit incluÃ­dos nas respostas

### ğŸ§  **Sistema de Aprendizado**
- **MÃ©todo Recomendado**: Use `/content/*` para melhor precisÃ£o
- **Treinamento**: Mais exemplos = maior precisÃ£o
- **PersistÃªncia**: PadrÃµes sÃ£o salvos automaticamente

### ğŸ”„ **Crawling Incremental**
- URLs jÃ¡ visitadas sÃ£o ignoradas por padrÃ£o
- Use `"force": true` para forÃ§ar recrawling
- Sistema detecta e evita pÃ¡ginas de catÃ¡logo automaticamente

## ğŸ†˜ Suporte e Troubleshooting

### ğŸ” **Verificar Status**
```bash
curl http://localhost:8081/health
```

### ğŸ“‹ **Logs Detalhados**
- Logs disponÃ­veis no console da aplicaÃ§Ã£o
- ClassificaÃ§Ãµes sÃ£o logadas com nÃ­vel DEBUG
- Erros incluem contexto detalhado

### ğŸ› **Problemas Comuns**
1. **Baixa PrecisÃ£o**: Adicione mais exemplos de treinamento
2. **Rate Limit**: Aguarde o reset ou use menos requisiÃ§Ãµes
3. **Sites InacessÃ­veis**: Verifique conectividade e robots.txt

## ğŸ“ Changelog

### v1.2.0 (Atual)
- âœ… Sistema de classificaÃ§Ã£o baseado em conteÃºdo
- âœ… DocumentaÃ§Ã£o Swagger completa
- âœ… PrecisÃ£o de 80% apÃ³s treinamento
- âœ… Interface web melhorada
- âœ… PersistÃªncia de padrÃµes aprendidos

### v1.1.0
- âœ… Gerenciamento de cidades e sites
- âœ… Sistema de aprendizado de padrÃµes (URL)
- âœ… Rate limiting implementado

### v1.0.0
- âœ… Crawling bÃ¡sico de propriedades
- âœ… API REST fundamental
- âœ… Interface web inicial

---

**ğŸ  Go Crawler API** - Sistema Inteligente de Crawling de ImÃ³veis  
ğŸ“– **DocumentaÃ§Ã£o sempre atualizada em:** [http://localhost:8081/docs](http://localhost:8081/docs)
